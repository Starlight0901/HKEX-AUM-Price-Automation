{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9kUJ-h-c2Ip",
        "outputId": "00657dd5-858b-49bd-b040-6190b73b8fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.22.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.0-py3-none-any.whl (475 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.22.0 trio-0.26.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install schedule"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI2rTE45SIBW",
        "outputId": "5f3b2aed-f642-4bd7-a68c-f609ab1fbf8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: schedule in /usr/local/lib/python3.10/dist-packages (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r64OGcNadFHN"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE2XfdtYemyq"
      },
      "outputs": [],
      "source": [
        "# Set up Selenium options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode for automation\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwvvYn-BdFp4"
      },
      "outputs": [],
      "source": [
        "def scrape_aum(url):\n",
        "\n",
        "  # Initialize the WebDriver\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "  driver.get(url)\n",
        "  time.sleep(5)  # Wait for the page to load\n",
        "\n",
        "  # Get the page source and parse it with BeautifulSoup\n",
        "  page_source = driver.page_source\n",
        "  soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "  # Locate the specific div containing the AUM data\n",
        "  div = soup.find('div', class_='left_list_item list_item_as')\n",
        "\n",
        "  if div:\n",
        "      # Extract the data\n",
        "      aum = div.find('dt', class_='col_aum').text.strip() if div.find('dt', class_='col_aum') else \"N/A\"\n",
        "      #current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "      aum_date = div.find('dt', class_='col_aum_date').text.strip() if div.find('dt', class_='col_aum_date') else \"N/A\"\n",
        "\n",
        "      return aum, aum_date\n",
        "  else:\n",
        "      print(\"Div not found. Please check the HTML structure and update the div selector.\")\n",
        "\n",
        "  # Close the Selenium driver\n",
        "  driver.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkg4iTG4dNnp"
      },
      "outputs": [],
      "source": [
        "# BOS_HSK, Date = scrape_aum(url = \"https://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products/Exchange-Traded-Products-Quote?sym=9008&sc_lang=en\")\n",
        "# print(BOS_HSK)\n",
        "# print(Date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kou8H6r2dQMW"
      },
      "outputs": [],
      "source": [
        "# CAM, Date = scrape_aum(url = \"https://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products/Exchange-Traded-Products-Quote?sym=9042&sc_lang=en\")\n",
        "# print(CAM)\n",
        "# print(Date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwQyJ_YkdUqQ"
      },
      "outputs": [],
      "source": [
        "# HGI, Date = scrape_aum(url = \"https://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products/Exchange-Traded-Products-Quote?sym=9439&sc_lang=en\")\n",
        "# print(HGI)\n",
        "# print(Date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywGLwllTdVa_"
      },
      "outputs": [],
      "source": [
        "# data = {\n",
        "#    'Date': [Date],\n",
        "#    'Bosera HashKey Bitcoin ETF (9008)': [BOS_HSK],\n",
        "#    'ChinaAMC Bitcoin ETF (9042)': [CAM],\n",
        "#    ' Harvest Bitcoin ETF  (9439)': [HGI]\n",
        "#}\n",
        "#df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0fQDXG6dsVu"
      },
      "outputs": [],
      "source": [
        "#df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUSfEAFads2X"
      },
      "outputs": [],
      "source": [
        "def web_scrape():\n",
        "  BOS_HSK, Date = scrape_aum(url = \"https://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products/Exchange-Traded-Products-Quote?sym=9008&sc_lang=en\")\n",
        "  HGI, Date = scrape_aum(url = \"https://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products/Exchange-Traded-Products-Quote?sym=9439&sc_lang=en\")\n",
        "  CAM, Date = scrape_aum(url = \"https://www.hkex.com.hk/Market-Data/Securities-Prices/Exchange-Traded-Products/Exchange-Traded-Products-Quote?sym=9042&sc_lang=en\")\n",
        "\n",
        "  csv_file = 'all_aum_data.csv'\n",
        "  try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "  except FileNotFoundError:\n",
        "    df = pd.DataFrame(columns=['Date', 'Bosera HashKey Bitcoin ETF (9008)', 'ChinaAMC Bitcoin ETF (9042)', 'Harvest Bitcoin ETF (9439)'])\n",
        "\n",
        "  # Check if the current date is already in the DataFrame\n",
        "  if Date not in df['Date'].values:\n",
        "    data = pd.DataFrame({\n",
        "      'Date': [Date],\n",
        "      'Bosera HashKey Bitcoin ETF (9008)': [BOS_HSK],\n",
        "      'ChinaAMC Bitcoin ETF (9042)': [CAM],\n",
        "      'Harvest Bitcoin ETF (9439)': [HGI]\n",
        "    })\n",
        "\n",
        "    # Append the data\n",
        "    df = pd.concat([df, data], ignore_index=True)\n",
        "\n",
        "    # Save the updated DataFrame to the CSV file\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(\"Update successfully.\")\n",
        "  else:\n",
        "    print(\"AData already recorded.\")\n",
        "  print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cu5oj1hyRQjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_scrape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNPMPuW6duhD",
        "outputId": "c8b47b81-bda6-42c6-9769-36d1fb2ffb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update successfully.\n",
            "                 Date Bosera HashKey Bitcoin ETF (9008)  \\\n",
            "0  (as at 5 Jul 2024)                         US$83.47M   \n",
            "\n",
            "  ChinaAMC Bitcoin ETF (9042) Harvest Bitcoin ETF (9439)  \n",
            "0                   US$86.56M                  US$40.19M  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dAN6KyzPd8-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zs1y-mSGH56S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}